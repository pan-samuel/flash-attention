#Flash Attention

These are my flash attention kernels. 

In SIMT, I optimize single percision flash attentio to outperform cuDNN and SPDA, which you can read here
